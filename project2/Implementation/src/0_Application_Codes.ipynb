{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import shutil  \n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue>Part A: Pre-processing Binary files to a dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set paths and random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1099\n",
    "raw_dir = '../raw'\n",
    "block_dir = '../blocks'\n",
    "data_good = '../dataset/good'\n",
    "data_bad = '../dataset/bad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process binary files to basic blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ProcessBinary as proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.generateBlocksFromBinary(raw_dir, block_dir)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create test ID and move blocks into \"dataset/good or dataset/bad  folder\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ExtractInstructions as ex\n",
    "import ExtractFeatures as ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.createTestID(block_dir,data_good,data_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract instruction and operands from basic blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_type = ex.getCombinedOperands(\"../other_files/Combined_Operands.txt\")\n",
    "set_filename_good, good_instr = ex.extractInstructionsAndOps(data_good, combine_type)\n",
    "set_filename_bad, bad_instr = ex.extractInstructionsAndOps(data_bad, combine_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create target label (0/1) and combined good and bad function blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_combined, corpus_combined, target_combined = ef.createTrainSetandLabel(good_instr, bad_instr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract Features using Counter Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_arr, features_name = ef.countVectorizer(corpus_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature extraction: \")\n",
    "print(\"\\nTotal number of features: \",len(features_name))\n",
    "print(features_name)\n",
    "print(counter_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Export counter vectors with features to excel file: \"TrainData.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef.exportToExcel(\"../other_files/TrainData.xlsx\", features_name, counter_arr, id_combined, target_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue>Part B: Pre-processing dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import data from an excel file and save to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../other_files/TrainData.xlsx', index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting datset into training, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_c = df.target\n",
    "X_c = df.drop(['fname', 'target','constant_op3'], axis=1)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, stratify=y_c, random_state = random_seed, test_size= 0.10)\n",
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_train_c, y_train_c, stratify=y_train_c, random_state = random_seed, test_size= 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_train = y_train_c.value_counts()\n",
    "per_train = y_train_c.value_counts(normalize=True)\n",
    "cnt_val = y_val_c.value_counts()\n",
    "per_val = y_val_c.value_counts(normalize=True)\n",
    "cnt_test = y_test_c.value_counts()\n",
    "per_test = y_test_c.value_counts(normalize=True)\n",
    "\n",
    "pd.DataFrame({'Train_Count': cnt_train,'Val_Count': cnt_val,'Test_Count': cnt_test, 'Train_Percent': per_train, 'Val_Percent': per_val, 'Test_Percent': per_test}).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalize data with z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train_c)\n",
    "X_train_norm_c = ss.transform(X_train_c)\n",
    "X_val_norm_c = ss.transform(X_val_c)\n",
    "X_test_norm_c  = ss.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train_c),y_train_c)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue>Part C: Machine Learning Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MLModels as ml\n",
    "import MLModelsEvaluation as mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set Hyperparameters for tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_list = [30, 50, 100, 200]\n",
    "ET_list = [100, 200, 300]\n",
    "MD_list = [20, 40, 60, 80, 100]\n",
    "CW_list = [ {0:0.71, 1:1.64} ]\n",
    "CG_list = [ 0.0001, 0.001, 0.01, 0.1, 1, 10 ,100, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 Build decision tree from Gridsearch CV\n",
    "dt = ml.buildDecisionTreeGS(random_seed, X_train_c, y_train_c, MS_list, MD_list, CW_list)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 fit model\n",
    "dt.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 Predict target class\n",
    "pred_train = dt.predict(X_train_c)\n",
    "pred_val = dt.predict(X_val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 Evaluate Models \n",
    "print(\"Accuracy Scores (Train): \",mle.computeAccuracy(y_train_c, pred_train))\n",
    "print(\"Accuracy Scores (Validation): \",mle.computeAccuracy(y_val_c, pred_val))\n",
    "mle.showMetrics(\"Confusion Matrix for Best Decision Tree\", y_val_c, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 Compute feature importants from Decision Tree\n",
    "top_features_dt = ml.getImportantFeatures(20,X_train_c, dt)\n",
    "print(top_features_dt)\n",
    "ml.plotImportantFeatures(top_features_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Build random forest from Gridsearch CV\n",
    "rf =ml.buildRandomForestGS(random_seed, X_train_c, y_train_c,ET_list, MS_list, MD_list, CW_list)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 Fit model\n",
    "rf.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Predict target class\n",
    "pred_train_rf = rf.predict(X_train_c)\n",
    "pred_val_rf = rf.predict(X_val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Evaluate Models \n",
    "print(\"Accuracy Scores (Train): \",mle.computeAccuracy(y_train_c, pred_train_rf))\n",
    "print(\"Accuracy Scores (Validation): \",mle.computeAccuracy(y_val_c, pred_val_rf))\n",
    "mle.showMetrics(\"Confusion Matrix for Best Random Forest\", y_val_c, pred_val_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4 Compute feature importants from Random Forest\n",
    "top_features_rf = ml.getImportantFeatures(20,X_train_c, rf)\n",
    "print(top_features_rf)\n",
    "ml.plotImportantFeatures(top_features_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 Build the Best SVM\n",
    "svm = ml.buildCustomSVM(100, 0.01, {0: 0.71, 1: 1.64} )\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 Fit model\n",
    "svm.fit(X_train_norm_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3 Predict class labels\n",
    "pred_train = svm.predict(X_train_norm_c)\n",
    "pred_val = svm.predict(X_val_norm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4 Evaluate Model\n",
    "print(\"Accuracy Scores (Train): \",mle.computeAccuracy(y_train_c, pred_train))\n",
    "print(\"Accuracy Scores (Validation): \",mle.computeAccuracy(y_val_c, pred_val))\n",
    "mle.showMetrics(\"Confusion Matrix for Best SVM\", y_val_c, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue>Part D: Deep Learning Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DLModels as dl\n",
    "import DLModelsEvaluation as dle\n",
    "import DLModelsThresholds as dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reshape the input to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_DL, X_val_DL, X_test_DL = dl.reshape_X(X_train_norm_c, X_val_norm_c, X_test_norm_c)\n",
    "y_train_dl, y_val_dl, y_test_dl = dl.reshape_Y(y_train_c, y_val_c, y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_DL.shape)\n",
    "print(X_val_DL.shape)\n",
    "print(X_test_DL.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class_weights\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train_c),y_train_c)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dl.buildDLmodel(X_train_DL.shape[2], 'tanh', 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile and Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1 compile the model\n",
    "compiled_model = dl.compileDLModel(model,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 For a learning rate\n",
    "import tensorflow as tf\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.001\n",
    "    \n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 fit model and save tranining results\n",
    "history, mymodel = dl.fitDLmodel(compiled_model, X_train_DL, y_train_dl, X_val_DL, y_val_dl, 32, 50, {0:0.71, 1:1.64},callback)\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5.1 Plot Loss Graph\n",
    "dle.plotLoss(history, 0, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2Plot Accuracy Graph\n",
    "dle.plotAccuracy(history, 0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds= mymodel.predict(X_val_DL)\n",
    "Thresholds = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "dlt.plotAccuracyandF1(Thresholds,y_val_c, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation the Best Deep Learning Model ( Test set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.2 evaluate the best models\n",
    "preds= mymodel.predict(X_test_DL)\n",
    "predicted_class  = dlt.getPredictedLabel(preds, 0.45)\n",
    "print(\"Accuracy Scores (Test): \",dle.computeAccuracy(y_test_c, predicted_class))\n",
    "dle.showMetrics(\"Confusion Matrix for DL\", y_test_c, predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
